---
title: "Prospectus"
date-modified: today
date-format: medium
author:
  - name: "Linzhuo Li"
    email: lil23@wfu.edu
    affiliation: "Wake Forest University"
abstract: |
  This is a sample prospectus. It is a work in progress and will be updated as needed as the semester progresses.
keywords:
  - prospectus
  - sample
citation: true
bibliography: ../bibliography.bib
---

<!--
Summary:

You've definitely made some progress. The goals of your research are taking on more shape, but it is vital that you include references to the literature that you are using to build your research question. This will help you to build a more comprehensive literature review and to ensure that your research question is well-grounded in the existing literature. Without this grounding, it can be very easy to go off track and try to do too much, or worse, to miss important aspects you could have concentrated your efforts on.

Overall, I'm excited to see your progress and I think you are on the right track. Keep up the good work!

-->



# Introduction

Study Corpus linguistics of English grammar

## Literature review

Most previous literature on the corpus study of English grammar is for educational purposes. Numerous contemporary theories of language comprehension emphasize the significance of distributional frequencies in determining the relative accessibility or processing ease linked to specific lexical items or sentence structures. Despite this emphasis, there is a scarcity of comprehensive analyses on structural frequencies, and minimal attention has been devoted to assessing the suitability of employing any specific corpus frequencies for modeling human language. The current research question is to discover the significant characteristics of English grammar.

<!--

This overview is a good start, but it is important to weave the literature you have been using to build your research question into this section.

So for example, if you have a reference in your `.bib` file, you will want to cite here with the appropiate citation key (@Author2023)

-->


# Methods

1. Data Acquisition:\
The study utilizes diverse English texts from reputable linguistic databases like the British National Corpus (BNC) and the Corpus of Contemporary American English (COCA).

2. Data Organization:\
Texts are segmented into sentences and tokenized for linguistic unit extraction. The dataset is then formatted for structured computational analysis.

3. Data Enrichment:\
Linguistic annotations and metadata such as part-of-speech tags and syntactic parse trees are added to enhance the corpus, enabling nuanced insights.

4. Feature Selection and Engineering:\
Various linguistic features like word frequencies, collocational patterns, and syntactic constructions are chosen for analysis. Feature engineering may be used to derive novel linguistic attributes.

5. Analysis Techniques:\
Quantitative and computational linguistics methods including frequency analysis, distributional analysis, and machine learning models are employed to identify patterns and trends in the data.

6. Evaluation Process:\
Exploratory data analysis, inter-annotator agreement measures, and cross-validation techniques ensure the validity and reliability of the findings across different linguistic contexts.

<!--

This is a general outline of your methods. It is a good start, but you will want to include more detail about the specific methods you will use to analyze the data. You will need to include more detail about the data source in terms of what the data source is (data origin informatiion), the original data format and structure, and how you will transform the data for analysis.

In terms of the analysis, you will want to follow our class approach of determining the research aim (explore, predict, or infer) and specifiying the methods you will use to answer the research question according to the research question and the dataset variables.

-->


## Data preparation

The data for this study originates from diverse English texts sourced from reputable linguistic databases such as the British National Corpus (BNC) and the Corpus of Contemporary American English (COCA). Collection involves systematic retrieval based on predefined criteria followed by thorough cleaning to eliminate noise and inconsistencies. Additionally, the dataset is enriched through linguistic annotations including part-of-speech tags and syntactic structures. Normalization techniques ensure consistency, while sampling and partitioning may be employed for manageability. This rigorous process aims to establish a high-quality dataset, facilitating the subsequent analysis of English grammar characteristics with reliability and depth.

<!--

General question here: I'm still not clear what the research question is. And for that reason, I'm not sure what you are trying to do with the data, nor why both the BNC and COCA are both necessary. From our discussion yesterday (4/23/24), I understood that you were interested in the using the COCA for analyzing adjective use in some fashion. But what you plan to do and the reasoning why you plan to do is not clear.


More specifically to the data preparation, what is it about syntactic structures that you are interested in? Again, from our discussion yesterday, I did not get the sense that syntactic structure would be a component of your analysis. --I could be wrong, but this is why you need to develop a stronger introduction (with references) to the literature that you are using to build your research question and a more concreate research question. Make sure to address an issue that you can communicate to others the significance of your planned research. Without this, it is difficult to understand what you are trying to do and why you are trying to do it.

-->

## Data analysis

In analyzing English grammar characteristics, the study employs a careful selection of linguistic features, including word frequencies, collocational patterns, and syntactic structures, further refined through feature engineering techniques. Quantitative and computational linguistics methods such as frequency and distributional analysis, alongside machine learning models and natural language processing algorithms, unveil nuanced patterns within the corpus. Rigorous evaluation, encompassing exploratory data analysis, measures of inter-annotator agreement, and cross-validation techniques, ensures the credibility and reliability of the findings across diverse linguistic contexts and datasets, establishing a robust foundation for deriving meaningful insights.

<!--

There's a long list of things you plan to do here, but it is not clear how you plan to do them nor why they matter for what you are trying to do.

-->


# Expected results

The analysis is expected to reveal prominent structural patterns in English grammar, including collocational patterns and syntactic constructions. These findings may elucidate language comprehension mechanisms and processing ease. Moreover, insights from corpus-based frequencies could refine linguistic theories, inform pedagogy, and advance computational language modeling, impacting Linguistics and language science.


<!--

Again, you are shooting ideas from lots of areas and without a clear research question, it is difficult to understand what you are trying to do and why you are trying to do it.


-->

# Communication plan

The study's findings will be disseminated through multiple channels to maximize impact. The primary audience includes researchers and scholars in linguistics, corpus linguistics, and language processing. The results will be presented in academic conferences and peer-reviewed journals, ensuring visibility within the scholarly community. Additionally, efforts will be made to share key insights through online platforms, including research blogs and social media, to engage a broader audience interested in language science and computational linguistics. This comprehensive communication plan aims to facilitate knowledge exchange and foster collaboration across disciplinary boundaries.


<!--

OK.

-->

# Conclusion

This section provides a summary of the research proposal and its potential impact on the field of Linguistics and language science. It should include a clear statement of the significance of the research question and the potential contributions of the study.

# References

This section includes a list of sources cited in the prospectus. It should be formatted according to the citation style used in the field of Linguistics and language science.

# Appendix {.appendix}

This section includes any additional information that is relevant to the prospectus, such as data sources, code, or other supplementary materials.

# research statement

My research focuses on advancing the understanding of English grammar through corpus linguistics analysis. By examining distributional frequencies and structural patterns in diverse English texts, I aim to uncover significant characteristics of language comprehension and processing ease. My study contributes to the field of linguistics by refining existing theories and models and informing pedagogical approaches. Through rigorous analysis and dissemination efforts, I seek to engage both academic and broader communities interested in language science and computational linguistics, fostering knowledge exchange and collaboration across.

# Brainstorming

For addressing the research problem of uncovering significant characteristics of English grammar, ideal data would include diverse English texts from reputable linguistic databases like the British National Corpus (BNC) and the Corpus of Contemporary American English (COCA). These datasets should cover various genres, styles, and registers with annotated linguistic features such as part-of-speech tags and syntactic structures, facilitating structured computational analysis. While BNC and COCA align well, misalignment may occur in specific linguistic features or genres, necessitating the curation of supplementary datasets to fill gaps. Data should be structured for segmentation, tokenization, and standardized annotation formats to ensure consistency.


# Draft a data preparation strategy

Acquisition: Obtain diverse English texts from BNC and COCA, ensuring representation across genres and linguistic contexts.
Curation: Curate supplementary datasets to address misalignments in linguistic features or genres. Standardize annotation formats across datasets.
Transformation: Preprocess data by segmenting into sentences, tokenizing, and adding linguistic annotations like part-of-speech tags and syntactic structures.
Normalization: Standardize data formats and structures across datasets. Apply normalization techniques to eliminate noise and inconsistencies.
Validation: Validate curated datasets through exploratory data analysis and inter-annotator agreement measures to ensure reliability for subsequent analysis.

# Assessing your progress

<!-- Note: You may consider add more markdown formatting to make this easier to read. -->

What did you learn?

corpus linguistics study is mush complex than I expected. <!-- it can be! ;) -->

What was most/ least challenging?

Finding the appropriate materials of the study and choosing the method of handle them. <!-- This is a common challenge in research. -->

What resources did you consult?
Google scholar and wiki and some random websites that explain corpus linguistic study. <!-- You still need to document and include references in describing your research process as well as in your references section. It's not clear what you've consulted to arrive at your research question and methods. The literature review should be more comprehensive not just for the prospectus but for your research process. You will save time in the long run by documenting your research process as you go. -->

What more would you like to know about?

how to deal with huge amount of text effectively. <!-- This is a great question! You will first want to know what 'huge amount' means. For most research, R is perfectly capable of handling large datasets. You should do some more research on the data sources that you expect to use in this research and gauge the size of the data you will have access to and in what format. -->
